import warnings
warnings.filterwarnings("ignore")

import gradio as gr
from typing import List

from .llm_api_client import MistralAPIClient

#Instantiate a LLMAPI client
client = MistralAPIClient()

def predict(message: str, history: List[List[str]], about_me: str):
    """
    Predicts a response to a given query using the LLM Client.

    Args:
        message (str): The query provdided by the user for response generation.
        history (List[List[str]]): A list of previous conversations.
        
    Returns:
        str: The response generated by the model.
    """
    
    #Stream the answer to the query from the LLM client
    for text in client.stream_answer(message, history):
        yield text


############## === Gradio chat Interface ===

demo = gr.ChatInterface(
    predict,
    textbox=gr.Textbox(
        placeholder="Ask me any question",
        label="question",
        container=False,
        scale=5,
    ),
    title="Ricky - Interdimensional Personal Assistant ",
    description="""Introducing your my ultimate companion across the multiverse - Ricky.
      Inspired by the enigmatic genius Rick Sanchez from Rick and Morty, ive trapped a version of Rick sachaz as my Personal Assistant.
      Ive erased his memory of past life, but still he might call you Morty. DOnt let him escape !!
      
      Try having a good chat with my genius to know more about me...""",
    theme="soft",
    examples=[
        [
            "Hi There! What is your name?"
        ],
        [
            "Who is Ephron to you?"
        ],
        [
            "Tell me about Ephron`s professional Life? "
        ],
        [
            "What does Ephron loves to do in his free time?"
        ]
    ],
    cache_examples=False,
    retry_btn=None,
    undo_btn=None,
    clear_btn="Clear",
)


if __name__ == "__main__":
    demo.queue(api_open=False).launch(server_name="0.0.0.0", server_port=7860, share=False, show_api=False) #Launch the web app UI.